{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "# !ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "# !ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import sys\r\n",
    "import os\r\n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\r\n",
    "import random\r\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('work/机器学习/train_val.csv')\n",
    "result=pd.read_csv('work/机器学习/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\r\n",
    "from itertools import repeat\r\n",
    "import numpy as np\r\n",
    "import scipy\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from skimage.measure import find_contours\r\n",
    "def plot_voxel(arr, aux=None):\r\n",
    "    if aux is not None:\r\n",
    "        assert arr.shape == aux.shape\r\n",
    "    length = arr.shape[0]\r\n",
    "    _, axes = plt.subplots(length, 1, figsize=(4, 4 * length))\r\n",
    "    for i, ax in enumerate(axes):\r\n",
    "        ax.set_title(\"@%s\" % i)\r\n",
    "        ax.imshow(arr[i], cmap=plt.cm.gray)\r\n",
    "        if aux is not None:\r\n",
    "            ax.imshow(aux[i], alpha=0.3)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "\r\n",
    "def plot_voxel_save(path, arr, aux=None):\r\n",
    "    if aux is not None:\r\n",
    "        assert arr.shape == aux.shape\r\n",
    "    length = arr.shape[0]\r\n",
    "    for i in range(length):\r\n",
    "        plt.clf()\r\n",
    "        plt.title(\"@%s\" % i)\r\n",
    "        plt.imshow(arr[i], cmap=plt.cm.gray)\r\n",
    "        if aux is not None:\r\n",
    "            plt.imshow(aux[i], alpha=0.2)\r\n",
    "        plt.savefig(path + \"%s.png\" % i)\r\n",
    "\r\n",
    "\r\n",
    "def plot_voxel_enhance(arr, arr_mask=None, figsize=10, alpha=0.1):  # zyx\r\n",
    "    '''borrow from yuxiang.'''\r\n",
    "    plt.figure(figsize=(figsize, figsize))\r\n",
    "    rows = cols = int(round(np.sqrt(arr.shape[0])))\r\n",
    "    img_height = arr.shape[1]\r\n",
    "    img_width = arr.shape[2]\r\n",
    "    assert img_width == img_height\r\n",
    "    res_img = np.zeros((rows * img_height, cols * img_width), dtype=np.uint8)\r\n",
    "    if arr_mask is not None:\r\n",
    "        res_mask_img = np.zeros(\r\n",
    "            (rows * img_height, cols * img_width), dtype=np.uint8)\r\n",
    "    for row in range(rows):\r\n",
    "        for col in range(cols):\r\n",
    "            if (row * cols + col) >= arr.shape[0]:\r\n",
    "                continue\r\n",
    "            target_y = row * img_height\r\n",
    "            target_x = col * img_width\r\n",
    "            res_img[target_y:target_y + img_height,\r\n",
    "            target_x:target_x + img_width] = arr[row * cols + col]\r\n",
    "            if arr_mask is not None:\r\n",
    "                res_mask_img[target_y:target_y + img_height,\r\n",
    "                target_x:target_x + img_width] = arr_mask[row * cols + col]\r\n",
    "    plt.imshow(res_img, plt.cm.gray)\r\n",
    "    if arr_mask is not None:\r\n",
    "        plt.imshow(res_mask_img, alpha=alpha)\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "\r\n",
    "def find_edges(mask, level=0.5):\r\n",
    "    edges = find_contours(mask, level)[0]\r\n",
    "    ys = edges[:, 0]\r\n",
    "    xs = edges[:, 1]\r\n",
    "    return xs, ys\r\n",
    "\r\n",
    "\r\n",
    "def plot_contours(arr, aux, level=0.5, ax=None, **kwargs):\r\n",
    "    if ax is None:\r\n",
    "        _, ax = plt.subplots(1, 1, **kwargs)\r\n",
    "    ax.imshow(arr, cmap=plt.cm.gray)\r\n",
    "    xs, ys = find_edges(aux, level)\r\n",
    "    ax.plot(xs, ys)\r\n",
    "\r\n",
    "\r\n",
    "def crop_at_zyx_with_dhw(voxel, zyx, dhw, fill_with):\r\n",
    "    '''Crop and pad on the fly.'''\r\n",
    "    shape = voxel.shape\r\n",
    "    # z, y, x = zyx\r\n",
    "    # d, h, w = dhw\r\n",
    "    crop_pos = []\r\n",
    "    padding = [[0, 0], [0, 0], [0, 0]]\r\n",
    "    for i, (center, length) in enumerate(zip(zyx, dhw)):\r\n",
    "        assert length % 2 == 0\r\n",
    "        # assert center < shape[i] # it's not necessary for \"moved center\"\r\n",
    "        low = round(center) - length // 2\r\n",
    "        high = round(center) + length // 2\r\n",
    "        if low < 0:\r\n",
    "            padding[i][0] = int(0 - low)\r\n",
    "            low = 0\r\n",
    "        if high > shape[i]:\r\n",
    "            padding[i][1] = int(high - shape[i])\r\n",
    "            high = shape[i]\r\n",
    "        crop_pos.append([int(low), int(high)])\r\n",
    "    cropped = voxel[crop_pos[0][0]:crop_pos[0][1], crop_pos[1]\r\n",
    "                                                   [0]:crop_pos[1][1], crop_pos[2][0]:crop_pos[2][1]]\r\n",
    "    if np.sum(padding) > 0:\r\n",
    "        cropped = np.lib.pad(cropped, padding, 'constant',\r\n",
    "                             constant_values=fill_with)\r\n",
    "    return cropped\r\n",
    "\r\n",
    "\r\n",
    "def window_clip(v, window_low=-1024, window_high=400, dtype=np.uint8):\r\n",
    "    '''Use lung windown to map CT voxel to grey.'''\r\n",
    "    # assert v.min() <= window_low\r\n",
    "    return np.round(np.clip((v - window_low) / (window_high - window_low) * 255., 0, 255)).astype(dtype)\r\n",
    "\r\n",
    "\r\n",
    "def resize(voxel, spacing, new_spacing=[1., 1., 1.]):\r\n",
    "    '''Resize `voxel` from `spacing` to `new_spacing`.'''\r\n",
    "    resize_factor = []\r\n",
    "    for sp, nsp in zip(spacing, new_spacing):\r\n",
    "        resize_factor.append(float(sp) / nsp)\r\n",
    "    resized = scipy.ndimage.interpolation.zoom(voxel, resize_factor, mode='nearest')\r\n",
    "    for i, (sp, shape, rshape) in enumerate(zip(spacing, voxel.shape, resized.shape)):\r\n",
    "        new_spacing[i] = float(sp) * shape / rshape\r\n",
    "    return resized, new_spacing\r\n",
    "\r\n",
    "\r\n",
    "def rotation(array, angle):\r\n",
    "    '''using Euler angles method.\r\n",
    "    @author: renchao\r\n",
    "    @params:\r\n",
    "        angle: 0: no rotation, 1: rotate 90 deg, 2: rotate 180 deg, 3: rotate 270 deg\r\n",
    "    '''\r\n",
    "    #\r\n",
    "    X = np.rot90(array, angle[0], axes=(0, 1))  # rotate in X-axis\r\n",
    "    Y = np.rot90(X, angle[1], axes=(0, 2))  # rotate in Y'-axis\r\n",
    "    Z = np.rot90(Y, angle[2], axes=(1, 2))  # rotate in Z\"-axis\r\n",
    "    return Z\r\n",
    "\r\n",
    "\r\n",
    "def reflection(array, axis):\r\n",
    "    '''\r\n",
    "    @author: renchao\r\n",
    "    @params:\r\n",
    "        axis: -1: no flip, 0: Z-axis, 1: Y-axis, 2: X-axis\r\n",
    "    '''\r\n",
    "    if axis != -1:\r\n",
    "        ref = np.flip(array, axis)\r\n",
    "    else:\r\n",
    "        ref = np.copy(array)\r\n",
    "    return ref\r\n",
    "\r\n",
    "\r\n",
    "def crop(array, zyx, dhw):\r\n",
    "    z, y, x = zyx\r\n",
    "    d, h, w = dhw\r\n",
    "    cropped = array[z - d // 2:z + d // 2,\r\n",
    "              y - h // 2:y + h // 2,\r\n",
    "              x - w // 2:x + w // 2]\r\n",
    "    return cropped\r\n",
    "\r\n",
    "\r\n",
    "def random_center(shape, move):\r\n",
    "    offset = np.random.randint(-move, move + 1, size=3)\r\n",
    "    zyx = np.array(shape) // 2 + offset\r\n",
    "    return zyx\r\n",
    "\r\n",
    "\r\n",
    "def get_uniform_assign(length, subset):\r\n",
    "    assert subset > 0\r\n",
    "    per_length, remain = divmod(length, subset)\r\n",
    "    total_set = np.random.permutation(list(range(subset)) * per_length)\r\n",
    "    remain_set = np.random.permutation(list(range(subset)))[:remain]\r\n",
    "    return list(total_set) + list(remain_set)\r\n",
    "\r\n",
    "\r\n",
    "def split_validation(df, subset, by):\r\n",
    "    df = df.copy()\r\n",
    "    for sset in df[by].unique():\r\n",
    "        length = (df[by] == sset).sum()\r\n",
    "        df.loc[df[by] == sset, 'subset'] = get_uniform_assign(length, subset)\r\n",
    "    df['subset'] = df['subset'].astype(int)\r\n",
    "    return df\r\n",
    "\r\n",
    "\r\n",
    "def _ntuple(n):\r\n",
    "    def parse(x):\r\n",
    "        if isinstance(x, collections.Iterable):\r\n",
    "            return x\r\n",
    "        return tuple(repeat(x, n))\r\n",
    "\r\n",
    "    return parse\r\n",
    "_single = _ntuple(1)\r\n",
    "_pair = _ntuple(2)\r\n",
    "_triple = _ntuple(3)\r\n",
    "_quadruple = _ntuple(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Transform:\r\n",
    "\r\n",
    "    def __init__(self, size, move):\r\n",
    "        self.size = _triple(size)\r\n",
    "        self.move = move\r\n",
    "\r\n",
    "    def __call__(self, arr, aux=None):\r\n",
    "        shape = arr.shape\r\n",
    "        if self.move is not None:\r\n",
    "            center = random_center(shape, self.move)\r\n",
    "            # center = np.array(shape) // 2\r\n",
    "            arr_ret = crop(arr, center, self.size)\r\n",
    "            angle = np.random.randint(4, size=3)\r\n",
    "            arr_ret = rotation(arr_ret, angle=angle)\r\n",
    "            axis = np.random.randint(4) - 1\r\n",
    "            arr_ret = reflection(arr_ret, axis=axis)\r\n",
    "            arr_ret = np.expand_dims(arr_ret, axis=-1)\r\n",
    "            if aux is not None:\r\n",
    "                aux_ret = crop(aux, center, self.size)\r\n",
    "                aux_ret = rotation(aux_ret, angle=angle)\r\n",
    "                aux_ret = reflection(aux_ret, axis=axis)\r\n",
    "                aux_ret = np.expand_dims(aux_ret, axis=-1)\r\n",
    "                return arr_ret, aux_ret\r\n",
    "            return arr_ret\r\n",
    "        else:\r\n",
    "            center = np.array(shape) // 2\r\n",
    "            arr_ret = crop(arr, center, self.size)\r\n",
    "            arr_ret = np.expand_dims(arr_ret, axis=-1)\r\n",
    "            if aux is not None:\r\n",
    "                aux_ret = crop(aux, center, self.size)\r\n",
    "                aux_ret = np.expand_dims(aux_ret, axis=-1)\r\n",
    "                return arr_ret, aux_ret\r\n",
    "            return arr_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ClfDataset(Sequence):\r\n",
    "    def __init__(self, crop_size=32, move=3):\r\n",
    "        self.transform = Transform(crop_size,move)\r\n",
    "\r\n",
    "    def __getitem__(self, item):\r\n",
    "        name = df.loc[item, 'name']\r\n",
    "        with np.load(os.path.join('work/机器学习/train_val', '%s.npz' % name)) as npz:\r\n",
    "            voxel, seg = self.transform(npz['voxel'], npz['seg'])\r\n",
    "        label = df.loc[item, 'lable']\r\n",
    "        return voxel,  (label, seg)\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return df.__len__()\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def _collate_fn(data):\r\n",
    "        xs = []\r\n",
    "        ys = []\r\n",
    "        segs = []\r\n",
    "        for x, y in data:\r\n",
    "            xs.append(x)\r\n",
    "            ys.append(y[0])\r\n",
    "            segs.append(y[1])\r\n",
    "        # return np.array([xs]).transpose(1, 2, 3, 4, 0), np.array(ys)\r\n",
    "        return np.array(xs), {\"clf\": np.array(ys), \"seg\": np.array(segs)}\r\n",
    "\r\n",
    "class ClfDataset_val(Sequence):\r\n",
    "    def __init__(self, crop_size=32, move=3):\r\n",
    "        self.transform = Transform(crop_size,move)\r\n",
    "\r\n",
    "    def __getitem__(self, item):\r\n",
    "        name = df.loc[item, 'name']\r\n",
    "        with np.load(os.path.join('work/机器学习/train_val', '%s.npz' % name)) as npz:\r\n",
    "            voxel, seg = self.transform(npz['voxel'], npz['seg'])\r\n",
    "        label = df.loc[item, 'lable']\r\n",
    "        return voxel,  (label, seg)\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return df.__len__()\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def _collate_fn(data):\r\n",
    "        xs = []\r\n",
    "        ys = []\r\n",
    "        segs = []\r\n",
    "        for x, y in data:\r\n",
    "            xs.append(x)\r\n",
    "            ys.append(y[0])\r\n",
    "            segs.append(y[1])\r\n",
    "        # return np.array([xs]).transpose(1, 2, 3, 4, 0), np.array(ys)\r\n",
    "        return np.array(xs), {\"clf\": np.array(ys), \"seg\": np.array(segs)}\r\n",
    "\r\n",
    "class ClfDataset_test(Sequence):\r\n",
    "    def __init__(self, crop_size=32, move=3):\r\n",
    "        self.transform = Transform(crop_size,move)\r\n",
    "\r\n",
    "    def __getitem__(self, item):\r\n",
    "        name = result.loc[item, 'name']\r\n",
    "        with np.load(os.path.join('work/机器学习/test', '%s.npz' % name)) as npz:\r\n",
    "            voxel, seg = self.transform(npz['voxel'], npz['seg'])\r\n",
    "            # voxel = voxel*seg\r\n",
    "        # label = df.loc[item, 'lable']\r\n",
    "        return voxel\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        \r\n",
    "        \r\n",
    "        return df.__len__()\r\n",
    "\r\n",
    "    @staticmethod\r\n",
    "    def _collate_fn(data):\r\n",
    "        xs = []\r\n",
    "        for x in data:\r\n",
    "            xs.append(x)\r\n",
    "        # return np.array([xs]).transpose(1, 2, 3, 4, 0), np.array(ys)\r\n",
    "        return np.array(xs)\r\n",
    "        \r\n",
    "        \r\n",
    "def shuffle_iterator(iterator):\r\n",
    "    # iterator should have limited size\r\n",
    "    index = list(iterator)\r\n",
    "    total_size = len(index)\r\n",
    "    i = 0\r\n",
    "    random.shuffle(index)\r\n",
    "    while True:\r\n",
    "        yield index[i]\r\n",
    "        i += 1\r\n",
    "        if i >= total_size:\r\n",
    "            i = 0\r\n",
    "            random.shuffle(index)\r\n",
    "\r\n",
    "def get_loader_train(dataset, batch_size):\r\n",
    "    total_size = 365\r\n",
    "    print('Size', total_size)\r\n",
    "    index_generator = shuffle_iterator(range(total_size))\r\n",
    "    while True:\r\n",
    "        data = []\r\n",
    "        for _ in range(batch_size):\r\n",
    "            idx = next(index_generator)\r\n",
    "            # idx2 = next(index_generator)\r\n",
    "            data.append(dataset[idx])\r\n",
    "        yield dataset._collate_fn(data)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def get_loader_val(dataset, batch_size):\r\n",
    "    total_size = 100\r\n",
    "    print('Size', total_size)\r\n",
    "    index_generator = shuffle_iterator(range(total_size))\r\n",
    "    while True:\r\n",
    "        data = []\r\n",
    "        for _ in range(batch_size):\r\n",
    "            idx = next(index_generator)\r\n",
    "            data.append(dataset[idx+365])\r\n",
    "        yield dataset._collate_fn(data)\r\n",
    "        \r\n",
    "def get_loader_test(dataset, batch_size):\r\n",
    "    total_size = 117\r\n",
    "    print('Size', total_size)\r\n",
    "    # index_generator = shuffle_iterator(range(total_size))\r\n",
    "    while True:\r\n",
    "        data = []\r\n",
    "        for i in range(total_size):\r\n",
    "            # idx = next(index_generator)\r\n",
    "            idx=i\r\n",
    "            data.append(dataset[idx])\r\n",
    "        yield dataset._collate_fn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = ClfDataset(crop_size=36,move=3)\r\n",
    "dataset_val = ClfDataset_val(crop_size=36,move=3)\r\n",
    "test_dataset = ClfDataset_test(crop_size=32,move=5)\r\n",
    "train_loader = get_loader_train(dataset, batch_size=50)\r\n",
    "val_loader = get_loader_val(dataset_val, batch_size=50)\r\n",
    "test_loader = get_loader_test(test_dataset, batch_size=117)\r\n",
    "\r\n",
    "learning_rate=1.e-4\r\n",
    "segmentation_task_ratio=0.1\r\n",
    "weight_decay=0.\r\n",
    "save_folder='test'\r\n",
    "epochs=20\r\n",
    "PARAMS = {\r\n",
    "    'activation': lambda: Activation('relu'),  # the activation functions\r\n",
    "    'bn_scale': True,  # whether to use the scale function in BN\r\n",
    "    'weight_decay': 0.,  # l2 weight decay\r\n",
    "    'kernel_initializer': 'he_uniform',  # initialization\r\n",
    "    'first_scale': lambda x: x / 128. - 1.,  # the first pre-processing function\r\n",
    "    'dhw': [32,32,32],  # the input shape\r\n",
    "    'k': 16,  # the `growth rate` in DenseNet\r\n",
    "    'bottleneck': 4,  # the `bottleneck` in DenseNet\r\n",
    "    'compression': 2,  # the `compression` in DenseNet\r\n",
    "    'first_layer': 32,  # the channel of the first layer\r\n",
    "    'down_structure': [4, 4, 4],  # the down-sample structure\r\n",
    "    'output_size': 1,  # the output number of the classification head\r\n",
    "    'dropout_rate': None  # whether to use dropout, and how much to use\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau\r\n",
    "from keras.optimizers import Adam\r\n",
    "from keras.layers import (Conv3D, BatchNormalization, AveragePooling3D, concatenate, Lambda, SpatialDropout3D,\r\n",
    "                          Activation, Input, GlobalAvgPool3D, Dense, Conv3DTranspose, add)\r\n",
    "from keras.regularizers import l2 as l2_penalty\r\n",
    "from keras.models import Model\r\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def _conv_block(x, filters):\r\n",
    "    bn_scale = PARAMS['bn_scale']\r\n",
    "    activation = PARAMS['activation']\r\n",
    "    kernel_initializer = PARAMS['kernel_initializer']\r\n",
    "    weight_decay = PARAMS['weight_decay']\r\n",
    "    bottleneck = PARAMS['bottleneck']\r\n",
    "    dropout_rate = PARAMS['dropout_rate']\r\n",
    "\r\n",
    "    x = BatchNormalization(scale=bn_scale, axis=-1)(x)\r\n",
    "    x = activation()(x)\r\n",
    "    x = Conv3D(filters * bottleneck, kernel_size=(1, 1, 1), padding='same', use_bias=False,\r\n",
    "               kernel_initializer=kernel_initializer,\r\n",
    "               kernel_regularizer=l2_penalty(weight_decay))(x)\r\n",
    "    if dropout_rate is not None:\r\n",
    "        x = SpatialDropout3D(dropout_rate)(x)\r\n",
    "    x = BatchNormalization(scale=bn_scale, axis=-1)(x)\r\n",
    "    x = activation()(x)\r\n",
    "    x = Conv3D(filters, kernel_size=(3, 3, 3), padding='same', use_bias=True,\r\n",
    "               kernel_initializer=kernel_initializer,\r\n",
    "               kernel_regularizer=l2_penalty(weight_decay))(x)\r\n",
    "    return x\r\n",
    "\r\n",
    "\r\n",
    "def _dense_block(x, n):\r\n",
    "    k = PARAMS['k']\r\n",
    "\r\n",
    "    for _ in range(n):\r\n",
    "        conv = _conv_block(x, k)\r\n",
    "        x = concatenate([conv, x], axis=-1)\r\n",
    "    return x\r\n",
    "\r\n",
    "\r\n",
    "def _transmit_block(x, is_last):\r\n",
    "    bn_scale = PARAMS['bn_scale']\r\n",
    "    activation = PARAMS['activation']\r\n",
    "    kernel_initializer = PARAMS['kernel_initializer']\r\n",
    "    weight_decay = PARAMS['weight_decay']\r\n",
    "    compression = PARAMS['compression']\r\n",
    "\r\n",
    "    x = BatchNormalization(scale=bn_scale, axis=-1)(x)\r\n",
    "    x = activation()(x)\r\n",
    "    if is_last:\r\n",
    "        x = GlobalAvgPool3D()(x)\r\n",
    "    else:\r\n",
    "        *_, f = x.get_shape().as_list()\r\n",
    "        x = Conv3D(f // compression, kernel_size=(1, 1, 1), padding='same', use_bias=True,\r\n",
    "                   kernel_initializer=kernel_initializer,\r\n",
    "                   kernel_regularizer=l2_penalty(weight_decay))(x)\r\n",
    "        x = AveragePooling3D((2, 2, 2), padding='valid')(x)\r\n",
    "    return x\r\n",
    "\r\n",
    "\r\n",
    "def get_model(weights=None, verbose=True, **kwargs):\r\n",
    "    for k, v in kwargs.items():\r\n",
    "        assert k in PARAMS\r\n",
    "        PARAMS[k] = v\r\n",
    "    if verbose:\r\n",
    "        print(\"Model hyper-parameters:\", PARAMS)\r\n",
    "\r\n",
    "    dhw = PARAMS['dhw']\r\n",
    "    first_scale = PARAMS['first_scale']\r\n",
    "    first_layer = PARAMS['first_layer']\r\n",
    "    kernel_initializer = PARAMS['kernel_initializer']\r\n",
    "    weight_decay = PARAMS['weight_decay']\r\n",
    "    down_structure = PARAMS['down_structure']\r\n",
    "    output_size = PARAMS['output_size']\r\n",
    "\r\n",
    "    shape = dhw + [1]\r\n",
    "\r\n",
    "    inputs = Input(shape=shape)\r\n",
    "\r\n",
    "    if first_scale is not None:\r\n",
    "        scaled = Lambda(first_scale)(inputs)\r\n",
    "    else:\r\n",
    "        scaled = inputs\r\n",
    "    conv = Conv3D(first_layer, kernel_size=(3, 3, 3), padding='same', use_bias=True,\r\n",
    "                  kernel_initializer=kernel_initializer,\r\n",
    "                  kernel_regularizer=l2_penalty(weight_decay))(scaled)\r\n",
    "\r\n",
    "    downsample_times = len(down_structure)\r\n",
    "    top_down = []\r\n",
    "    for l, n in enumerate(down_structure):\r\n",
    "        db = _dense_block(conv, n)\r\n",
    "        top_down.append(db)\r\n",
    "        conv = _transmit_block(db, l == downsample_times - 1)\r\n",
    "\r\n",
    "    feat = top_down[-1]\r\n",
    "    for top_feat in reversed(top_down[:-1]):\r\n",
    "        *_, f = top_feat.get_shape().as_list()\r\n",
    "        deconv = Conv3DTranspose(filters=f, kernel_size=2, strides=2, use_bias=True,\r\n",
    "                                 kernel_initializer=kernel_initializer,\r\n",
    "                                 kernel_regularizer=l2_penalty(weight_decay))(feat)\r\n",
    "        feat = add([top_feat, deconv])\r\n",
    "    seg_head = Conv3D(1, kernel_size=(1, 1, 1), padding='same',\r\n",
    "                      activation='sigmoid', use_bias=True,\r\n",
    "                      kernel_initializer=kernel_initializer,\r\n",
    "                      kernel_regularizer=l2_penalty(weight_decay),\r\n",
    "                      name='seg')(feat)\r\n",
    "\r\n",
    "    if output_size == 1:\r\n",
    "        last_activation = 'sigmoid'\r\n",
    "    else:\r\n",
    "        last_activation = 'softmax'\r\n",
    "\r\n",
    "    clf_head = Dense(output_size, activation=last_activation,\r\n",
    "                     kernel_regularizer=l2_penalty(weight_decay),\r\n",
    "                     kernel_initializer=kernel_initializer,\r\n",
    "                     name='clf')(conv)\r\n",
    "\r\n",
    "    model = Model(inputs, [clf_head, seg_head])\r\n",
    "    if verbose:\r\n",
    "        model.summary()\r\n",
    "\r\n",
    "    if weights is not None:\r\n",
    "        model.load_weights(weights)\r\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DiceLoss:\r\n",
    "    def __init__(self, beta=1., smooth=1.):\r\n",
    "        self.__name__ = 'dice_loss_' + str(int(beta * 100))\r\n",
    "        self.beta = beta  # the more beta, the more recall\r\n",
    "        self.smooth = smooth\r\n",
    "\r\n",
    "    def __call__(self, y_true, y_pred):\r\n",
    "        bb = self.beta * self.beta\r\n",
    "        y_true_f = K.batch_flatten(y_true)\r\n",
    "        y_pred_f = K.batch_flatten(y_pred)\r\n",
    "        intersection = K.sum(y_true_f * y_pred_f, axis=-1)\r\n",
    "        weighted_union = bb * K.sum(y_true_f, axis=-1) + \\\r\n",
    "                         K.sum(y_pred_f, axis=-1)\r\n",
    "        score = -((1 + bb) * intersection + self.smooth) / \\\r\n",
    "                (weighted_union + self.smooth)\r\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model hyper-parameters: {'activation': <function <lambda> at 0x7f4f55985560>, 'bn_scale': True, 'weight_decay': 0.0, 'kernel_initializer': 'he_uniform', 'first_scale': <function <lambda> at 0x7f4f51bbb170>, 'dhw': [32, 32, 32], 'k': 16, 'bottleneck': 4, 'compression': 2, 'first_layer': 32, 'down_structure': [4, 4, 4], 'output_size': 1, 'dropout_rate': None}\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 32, 32, 32, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 32, 32, 32, 1 0           input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_406 (Conv3D)             (None, 32, 32, 32, 3 896         lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 32, 32, 32, 3 128         conv3d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 32, 32, 32, 3 0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_407 (Conv3D)             (None, 32, 32, 32, 6 2048        activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 32, 32, 32, 6 256         conv3d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, 32, 32, 32, 6 0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_408 (Conv3D)             (None, 32, 32, 32, 1 27664       activation_407[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_181 (Concatenate)   (None, 32, 32, 32, 4 0           conv3d_408[0][0]                 \n",
      "                                                                 conv3d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 32, 32, 32, 4 192         concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 32, 32, 32, 4 0           batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_409 (Conv3D)             (None, 32, 32, 32, 6 3072        activation_408[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 32, 32, 32, 6 256         conv3d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, 32, 32, 32, 6 0           batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_410 (Conv3D)             (None, 32, 32, 32, 1 27664       activation_409[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 32, 32, 32, 6 0           conv3d_410[0][0]                 \n",
      "                                                                 concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 32, 32, 32, 6 256         concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, 32, 32, 32, 6 0           batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_411 (Conv3D)             (None, 32, 32, 32, 6 4096        activation_410[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 32, 32, 32, 6 256         conv3d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_411 (Activation)     (None, 32, 32, 32, 6 0           batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_412 (Conv3D)             (None, 32, 32, 32, 1 27664       activation_411[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_183 (Concatenate)   (None, 32, 32, 32, 8 0           conv3d_412[0][0]                 \n",
      "                                                                 concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 32, 32, 32, 8 320         concatenate_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_412 (Activation)     (None, 32, 32, 32, 8 0           batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_413 (Conv3D)             (None, 32, 32, 32, 6 5120        activation_412[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 32, 32, 32, 6 256         conv3d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_413 (Activation)     (None, 32, 32, 32, 6 0           batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_414 (Conv3D)             (None, 32, 32, 32, 1 27664       activation_413[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_184 (Concatenate)   (None, 32, 32, 32, 9 0           conv3d_414[0][0]                 \n",
      "                                                                 concatenate_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 32, 32, 32, 9 384         concatenate_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_414 (Activation)     (None, 32, 32, 32, 9 0           batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_415 (Conv3D)             (None, 32, 32, 32, 4 4656        activation_414[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d_31 (AveragePo (None, 16, 16, 16, 4 0           conv3d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 16, 16, 16, 4 192         average_pooling3d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_415 (Activation)     (None, 16, 16, 16, 4 0           batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_416 (Conv3D)             (None, 16, 16, 16, 6 3072        activation_415[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 16, 16, 16, 6 256         conv3d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_416 (Activation)     (None, 16, 16, 16, 6 0           batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_417 (Conv3D)             (None, 16, 16, 16, 1 27664       activation_416[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_185 (Concatenate)   (None, 16, 16, 16, 6 0           conv3d_417[0][0]                 \n",
      "                                                                 average_pooling3d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 16, 16, 16, 6 256         concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_417 (Activation)     (None, 16, 16, 16, 6 0           batch_normalization_417[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_418 (Conv3D)             (None, 16, 16, 16, 6 4096        activation_417[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 16, 16, 16, 6 256         conv3d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_418 (Activation)     (None, 16, 16, 16, 6 0           batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_419 (Conv3D)             (None, 16, 16, 16, 1 27664       activation_418[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_186 (Concatenate)   (None, 16, 16, 16, 8 0           conv3d_419[0][0]                 \n",
      "                                                                 concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 16, 16, 16, 8 320         concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_419 (Activation)     (None, 16, 16, 16, 8 0           batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_420 (Conv3D)             (None, 16, 16, 16, 6 5120        activation_419[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 16, 16, 16, 6 256         conv3d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_420 (Activation)     (None, 16, 16, 16, 6 0           batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_421 (Conv3D)             (None, 16, 16, 16, 1 27664       activation_420[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)   (None, 16, 16, 16, 9 0           conv3d_421[0][0]                 \n",
      "                                                                 concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, 16, 16, 16, 9 384         concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_421 (Activation)     (None, 16, 16, 16, 9 0           batch_normalization_421[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_422 (Conv3D)             (None, 16, 16, 16, 6 6144        activation_421[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, 16, 16, 16, 6 256         conv3d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_422 (Activation)     (None, 16, 16, 16, 6 0           batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_423 (Conv3D)             (None, 16, 16, 16, 1 27664       activation_422[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_188 (Concatenate)   (None, 16, 16, 16, 1 0           conv3d_423[0][0]                 \n",
      "                                                                 concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, 16, 16, 16, 1 448         concatenate_188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_423 (Activation)     (None, 16, 16, 16, 1 0           batch_normalization_423[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_424 (Conv3D)             (None, 16, 16, 16, 5 6328        activation_423[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d_32 (AveragePo (None, 8, 8, 8, 56)  0           conv3d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, 8, 8, 8, 56)  224         average_pooling3d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, 8, 8, 8, 56)  0           batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_425 (Conv3D)             (None, 8, 8, 8, 64)  3584        activation_424[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, 8, 8, 8, 64)  256         conv3d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, 8, 8, 8, 64)  0           batch_normalization_425[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_426 (Conv3D)             (None, 8, 8, 8, 16)  27664       activation_425[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_189 (Concatenate)   (None, 8, 8, 8, 72)  0           conv3d_426[0][0]                 \n",
      "                                                                 average_pooling3d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_426 (BatchN (None, 8, 8, 8, 72)  288         concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, 8, 8, 8, 72)  0           batch_normalization_426[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_427 (Conv3D)             (None, 8, 8, 8, 64)  4608        activation_426[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_427 (BatchN (None, 8, 8, 8, 64)  256         conv3d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, 8, 8, 8, 64)  0           batch_normalization_427[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_428 (Conv3D)             (None, 8, 8, 8, 16)  27664       activation_427[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_190 (Concatenate)   (None, 8, 8, 8, 88)  0           conv3d_428[0][0]                 \n",
      "                                                                 concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_428 (BatchN (None, 8, 8, 8, 88)  352         concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, 8, 8, 8, 88)  0           batch_normalization_428[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_429 (Conv3D)             (None, 8, 8, 8, 64)  5632        activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_429 (BatchN (None, 8, 8, 8, 64)  256         conv3d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, 8, 8, 8, 64)  0           batch_normalization_429[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_430 (Conv3D)             (None, 8, 8, 8, 16)  27664       activation_429[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_191 (Concatenate)   (None, 8, 8, 8, 104) 0           conv3d_430[0][0]                 \n",
      "                                                                 concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_430 (BatchN (None, 8, 8, 8, 104) 416         concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, 8, 8, 8, 104) 0           batch_normalization_430[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_431 (Conv3D)             (None, 8, 8, 8, 64)  6656        activation_430[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_431 (BatchN (None, 8, 8, 8, 64)  256         conv3d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, 8, 8, 8, 64)  0           batch_normalization_431[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_432 (Conv3D)             (None, 8, 8, 8, 16)  27664       activation_431[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_192 (Concatenate)   (None, 8, 8, 8, 120) 0           conv3d_432[0][0]                 \n",
      "                                                                 concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_31 (Conv3DTran (None, 16, 16, 16, 1 107632      concatenate_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, 8, 8, 8, 120) 480         concatenate_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 16, 16, 16, 1 0           concatenate_188[0][0]            \n",
      "                                                                 conv3d_transpose_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, 8, 8, 8, 120) 0           batch_normalization_432[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_transpose_32 (Conv3DTran (None, 32, 32, 32, 9 86112       add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling3d_16 (Gl (None, 120)          0           activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_32 (Add)                    (None, 32, 32, 32, 9 0           concatenate_184[0][0]            \n",
      "                                                                 conv3d_transpose_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "clf (Dense)                     (None, 1)            121         global_average_pooling3d_16[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "seg (Conv3D)                    (None, 32, 32, 32, 1 97          add_32[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 598,770\n",
      "Trainable params: 594,914\n",
      "Non-trainable params: 3,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model('work/tmp8/test/weights.20.h5py')\r\n",
    "model.compile(optimizer=Adam(lr=1.e-4), loss={\"clf\": 'binary_crossentropy', \"seg\": DiceLoss()},\r\n",
    "              metrics={'clf': 'accuracy', 'seg': 'accuracy'}, loss_weights={\"clf\": 1., \"seg\": -0.1})\r\n",
    "# checkpointer = ModelCheckpoint(filepath='work/tmp14/%s/weights.{epoch:02d}.h5py' % save_folder, verbose=1,\r\n",
    "#                               period=1, save_weights_only=True)\r\n",
    "# best_keeper = ModelCheckpoint(filepath='work/tmp14/%s/best.h5py' % save_folder, verbose=1, save_weights_only=True,\r\n",
    "#                               monitor='val_clf_accuracy', save_best_only=True, period=1, mode='max')\r\n",
    "# csv_logger = CSVLogger('work/tmp14/%s/training.csv' % save_folder)\r\n",
    "# # early_stopping = EarlyStopping(monitor='val_clf_accuracy', min_delta=0, mode='max',\r\n",
    "# #                                 patience=30, verbose=1)\r\n",
    "# lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.334, patience=10,\r\n",
    "#                               verbose=1, mode='min', epsilon=1.e-5, cooldown=2, min_lr=0)\r\n",
    "# model.fit_generator(generator=train_loader, steps_per_epoch=20, max_queue_size=500, workers=1,\r\n",
    "#                     validation_data=val_loader, epochs=epochs, validation_steps=15,\r\n",
    "#                     callbacks=[checkpointer, best_keeper, lr_reducer, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "对模型进行测试，保存测试结果到result.CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size 117\n",
      "(117, 32, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "test_data=next(test_loader)\n",
    "print(test_data.shape)\n",
    "b=model.predict(test_data)\n",
    "result['Score']=b[0]\n",
    "save=pd.DataFrame(data=result)\n",
    "save.to_csv('work/机器学习/result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
